```{r include=FALSE, cache=FALSE}
options(digits = 4, width = 80)
options(dplyr.print_min = 6, dplyr.print_max = 6)

knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  fig.align = 'center',
  tidy = FALSE
)

transparent_theme <- function() {
  library(ggplot2)
  thm <- 
    theme_bw() + 
    theme(
      panel.background = element_rect(fill = "transparent", colour = NA), 
      plot.background = element_rect(fill = "transparent", colour = NA),
      legend.position = "top",
      legend.background = element_rect(fill = "transparent", colour = NA),
      legend.key = element_rect(fill = "transparent", colour = NA)
    )
  theme_set(thm)
}

transparent_theme()

tmwr_version <- function() {
  dt <- Sys.Date()
  ver <- read.dcf("DESCRIPTION")[1, "Version"]
  paste0("Version ", ver, " (", dt, ")")
}

```
```{r resampling-setup, include = FALSE}
knitr::opts_chunk$set(fig.path = "figures/")
library(tidymodels)
```

# Resampling for evaluating performance  {#resampling}




```{r resampling-scheme, echo = FALSE, out.width = '65%'}
if (knitr:::is_html_output()) {
  file.copy("premade/resampling.svg", "_book/premade/resampling.svg")
  knitr::include_graphics("premade/resampling.svg")
} else {
  file.copy("premade/resampling.pdf", "_book/premade/resampling.pdf")
  knitr::include_graphics("premade/resampling.pdf")
}
```

The next three section provide details on three important resampling methods. 


## Cross-validation

Cross-validation is an old resampling technique. While there are a number of variations, the most common cross-validation method is called _V_-fold cross-validation. In this case, the data are randomly partitioned into _V_ sets of roughly equal size (called the "folds"). Common values of _V_ are 10 or 5. For illustration, _V_ = 3 is shown below for a data set of thirty training set points. 

```{r resampling-three-cv, echo = FALSE, out.width = '25%'}

if (knitr:::is_html_output()) {
  file.copy("premade/three-CV.svg", "_book/premade/three-CV.svg")
  knitr::include_graphics("premade/three-CV.svg")
} else {
  file.copy("premade/three-CV.pdf", "_book/premade/three-CV.pdf")
  knitr::include_graphics("premade/three-CV.pdf")
}
```

The number inside the symbols are the sample numbers while the color and shape of the symbols represent their randomly assigned folds. The assignment to folds can be done via random sampling or, as was discussed on Section \@ref(splitting-methods), stratified assignment can be used. 

For 3-fold cross-validation, the three iterations of resampling are illustrated below. The first iteration removes the data for the first fold and fits the model to the remaining two folds. This model is used to predict the data from the first fold and model performance is estimated from these data. On the second iteration, the model is fit not the first and third folds and the second fold is used to compute another set of performance metrics. A similar process is used for the third fold. 

The result is a collection of three replicates for each of the performance statistics. The final resampling estimate of performance averages each of the _V_ replicates. 


```{r resampling-three-cv-iter, echo = FALSE, out.width = '55%'}
if (knitr:::is_html_output()) {
  file.copy("premade/three-CV-iter.svg", "_book/premade/three-CV-iter.svg")
  knitr::include_graphics("premade/three-CV-iter.svg")
} else {
  file.copy("premade/three-CV-iter.pdf", "_book/premade/three-CV-iter.pdf")
  knitr::include_graphics("premade/three-CV-iter.pdf")
}
```


## Bootstrapping


## Rolling origin forcasting


## Estimating performance


Maybe inlcude some simple examples of comparing models using resampling (perhaps go full `tidyposterior`?)

