<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1 Introduction | Tidy Modeling with R</title>
  <meta name="description" content="Modeling of data is integral to science, business, politics, and many other aspects of our lives. The goals of this book are to: introduce neophytes to models and the tidyverse, demonstrate the tidymodels packages, and to outline good practices for the phases of the modeling process." />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="1 Introduction | Tidy Modeling with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Modeling of data is integral to science, business, politics, and many other aspects of our lives. The goals of this book are to: introduce neophytes to models and the tidyverse, demonstrate the tidymodels packages, and to outline good practices for the phases of the modeling process." />
  <meta name="github-repo" content="topepo/TMwR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1 Introduction | Tidy Modeling with R" />
  <meta name="twitter:site" content="@topepos" />
  <meta name="twitter:description" content="Modeling of data is integral to science, business, politics, and many other aspects of our lives. The goals of this book are to: introduce neophytes to models and the tidyverse, demonstrate the tidymodels packages, and to outline good practices for the phases of the modeling process." />
  

<meta name="author" content="Max Kuhn" />


<meta name="date" content="2019-12-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="a-tidyverse-primer.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">Tidy Modeling with R</a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Hello World</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#types-of-models"><i class="fa fa-check"></i><b>1.1</b> Types of models</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#some-terminology"><i class="fa fa-check"></i><b>1.2</b> Some terminology</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#where-does-modeling-fit-into-the-data-analysisscientific-process"><i class="fa fa-check"></i><b>1.3</b> Where does modeling fit into the data analysis/scientific process?</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#modeling-is-a-process-not-a-single-activity"><i class="fa fa-check"></i><b>1.4</b> Modeling is a <em>process</em>, not a single activity</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#outline-of-future-chapters"><i class="fa fa-check"></i><b>1.5</b> Outline of future chapters</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="a-tidyverse-primer.html"><a href="a-tidyverse-primer.html"><i class="fa fa-check"></i><b>2</b> A tidyverse primer</a><ul>
<li class="chapter" data-level="2.1" data-path="a-tidyverse-primer.html"><a href="a-tidyverse-primer.html#principles"><i class="fa fa-check"></i><b>2.1</b> Principles</a></li>
<li class="chapter" data-level="2.2" data-path="a-tidyverse-primer.html"><a href="a-tidyverse-primer.html#code"><i class="fa fa-check"></i><b>2.2</b> Code</a></li>
<li class="chapter" data-level="2.3" data-path="a-tidyverse-primer.html"><a href="a-tidyverse-primer.html#why-tidiness-is-important-for-modeling"><i class="fa fa-check"></i><b>2.3</b> Why tidiness is important for modeling</a></li>
<li class="chapter" data-level="2.4" data-path="a-tidyverse-primer.html"><a href="a-tidyverse-primer.html#some-additional-tidy-principals-for-modeling."><i class="fa fa-check"></i><b>2.4</b> Some additional tidy principals for modeling.</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-tale-of-two-models.html"><a href="a-tale-of-two-models.html"><i class="fa fa-check"></i><b>3</b> A tale of two models</a></li>
<li class="chapter" data-level="4" data-path="spending-our-data.html"><a href="spending-our-data.html"><i class="fa fa-check"></i><b>4</b> Spending our data</a></li>
<li class="chapter" data-level="5" data-path="how-good-is-our-model.html"><a href="how-good-is-our-model.html"><i class="fa fa-check"></i><b>5</b> How good is our model?</a></li>
<li class="chapter" data-level="6" data-path="feature-engineering.html"><a href="feature-engineering.html"><i class="fa fa-check"></i><b>6</b> Feature engineering</a></li>
<li class="chapter" data-level="7" data-path="a-model-workflow.html"><a href="a-model-workflow.html"><i class="fa fa-check"></i><b>7</b> A model workflow</a></li>
<li class="chapter" data-level="8" data-path="resampling-for-evaluating-performance.html"><a href="resampling-for-evaluating-performance.html"><i class="fa fa-check"></i><b>8</b> Resampling for evaluating performance</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Tidy Modeling with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>Models are mathematical tools that create equations that are intended to mimic the data given to them. These equations can be used for various purposes, such as: predicting future events, determining if there is a difference between several groups, as an aid to a map-based visualization, discovering novel patterns in the data that could be further investigated, and so on. Their utility hinges on their ability to be reductive; the primary influences in the data can be captured mathematically in a way that is useful.</p>
<p>Since the start of the 21st century, mathematical models have become ubiquitous in our daily lives, in both obvious and subtle ways. A typical day for many people might involve checking the weather to see when a good time would be to walk the dog, ordering a product from a website, typing (and autocorrecting) a text message to a friend, and checking email. In each of these instances, there is a good chance that some type of model was used in an assistive way. In some cases, the contribution of the model might be easily perceived (“You might also be interested in purchasing product <em>X</em>”) while in other cases the impact was the absence of something (e.g., spam email). Models are used to choose clothing that a customer might like, a molecule that should be evaluated as a drug candidate, and might even be the mechanism that a nefarious company uses avoid the discovery of cars that over-pollute. For better or worse, models are here to stay.</p>
<p>Two reasons that models permeate our lives are that software exists that facilitates their creation and that data has become more easily captured and accessible. In regard to software, it is obviously critical that software produces the <em>correct</em> equations that represent the data. For the most part, determining mathematical correctness is possible. However, the creation of an appropriate model hinges on a few other aspects.</p>
<p>First, it is important that it is easy to operate the software in a <em>proper way</em>. For example, the user interface should not be so arcane that the user would not know that they have inappropriately specified the wrong information. As an analogy, one might have a high quality kitchen measuring cup capable of great precision but if the chef adds a cup of salt instead of a cup of sugar, the results would be unpalatable. As a specific example of this issue, <span class="citation">Baggerly and Coombes (<a href="#ref-baggerly2009">2009</a>)</span> report myriad problems in the data analysis in a high profile computational biology publication. One of the issues was related to how the users were required to add the names of the model inputs. The user-interface of the software was poor enough that it was easy to <em>offset</em> the column names of the data from the actual data columns. In the analysis of the data, this resulted in the wrong genes being identified as important for treating cancer patients. This, and many other issues, led to the stoppage of numerous clinical trials <span class="citation">(Carlson <a href="#ref-Carlson2012">2012</a>)</span>.</p>
<p>If we are to expect high quality models, it is important that the software facilitate proper usage. <span class="citation">Abrams (<a href="#ref-abrams2003">2003</a>)</span> describes an interesting principle to live by:</p>
<blockquote>
<p>The Pit of Success: in stark contrast to a summit, a peak, or a journey across a desert to find victory through many trials and surprises, we want our customers to simply fall into winning practices by using our platform and frameworks.</p>
</blockquote>
<p>Data analysis software should also espouse this idea.</p>
<p>The second important aspect of model building is related to <em>scientific methodology</em>. For models that are used to make complex predictions, it can be easy to unknowingly commit errors related to logical fallacies or inappropriate assumptions. Many machine learning models are so adept at finding patterns, they can effortlessly find empirical patterns in the data that fail to reproduce later. Some of these types of methodological errors are insidious in that the issue might be undetectable until a later time when new data that contain the true result are obtained. In short, as our models become more powerful and complex it has also become easier to commit latent errors. This also relates to programming. Whenever possible, the software should be able to protect users from committing such mistakes. Software should make it easy for users to do the right thing.</p>
<p>These two aspects of model creation are crucial. Since tools for creating models are easily obtained and models can have such a profound impact, many more people are creating them. In terms of technical expertise and training, their backgrounds will vary. It is important that their tools be <em>robust</em> to the experience of the user. On one had, they tools should be powerful enough to create high-performance models but, on the other hand, should be easy to use in an appropriate way. This book describes a suite of software that can can create different types of models. The software has been designed with these additional characteristics in mind.</p>
<p>The software is based on the R programming language <span class="citation">(R Core Team <a href="#ref-baseR">2014</a>)</span>. R has been designed especially for data analysis and modeling. It is based on the <em>S language</em> which was created in the 1970’s to</p>
<blockquote>
<p>“turn ideas into software, quickly and faithfully” <span class="citation">(Chambers <a href="#ref-Chambers:1998">1998</a>)</span></p>
</blockquote>
<p>R is open-source and is provided free of charge. It is a powerful programming language that can be used for many different purposes but specializes in data analysis, modeling, and machine learning. R is easily <em>extensible</em>; it has a vast ecosystem of <em>packages</em>; these are mostly user-contributed modules that focus on a specific theme, such as modeling, visualization, and so on.</p>
<p>One collection of packages is called the <strong><em>tidyverse</em></strong> <span class="citation">(Wickham et al. <a href="#ref-tidyverse">2019</a>)</span>. The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. Several of these design philosophies are directly related to the aspects of software described above. Within the tidyverse, there is a set of packages specifically focused on modeling and these are usually referred to as the <strong><em>tidymodels</em></strong> packages. This book is an extended software manual for conducting modeling using the tidyverse. It shows how to use a set of packages, each with its own specific purpose, together to create high-quality models.</p>
<div id="types-of-models" class="section level2">
<h2><span class="header-section-number">1.1</span> Types of models</h2>
<p>Before proceeding, lets describe a taxa for types of models, grouped by <em>purpose</em>. While not exhaustive, most models fail into <em>at least</em> one of these categories:</p>
<p><strong>Descriptive Models</strong>: The purpose here would be to model the data so that it can be used to describe or illustrate characteristics of some data. The analysis might have no other purpose than to visually emphasize some trend or artifact in the data.</p>
<p>For example, large scale measurements of RNA have been possible for some time using <em>microarrays</em>. Early laboratory methods placed a biological sample on a small microchip. Very small locations on the chip would be able to assess a measure of signal based on the abundance of a specific RNA sequence. The chip would contain thousands (or more) outcomes, each a quantification of the RNA related to some biological process. However, there could be quality issued on the chip that might lead to poor results. A fingerprint accidentally left on a portion of the chip might cause inaccurate measurements when scanned.</p>
<p>An early methods for evaluating such issues where <em>probe-level models</em>, or PLM’s <span class="citation">(Bolstad <a href="#ref-bolstad2004">2004</a>)</span>. A statistical model would be created that accounted for the <em>known</em> differences for the data from the chip, such as the RNA sequence, the type of sequence and so on. If there were other, unwanted factors in the data, these would be contained in the model residuals. When the residuals were plotted by their location on the chip, a good quality chip would show no patterns. When an issue did occur, some sort of spatial pattern would be discernible. Often the type of pattern would suggest the underlying issue (e.g. a fingerprint) and a possible solution (wipe the chip off and rescan). Figure <a href="introduction.html#fig:descr-examples">1.1</a>(a) shows an application of this method for two microarrays taken from <span class="citation">Gentleman et al. (<a href="#ref-Gentleman2005">2005</a>)</span>. The images show two different colors; red is where the signal intensity was larger than the model expects while the blue color shows lower than expected values. The left-hand panel demonstrates a fairly random pattern while the right-hand panel shows some type of unwanted artifact.</p>
<div class="figure" style="text-align: center"><span id="fig:descr-examples"></span>
<img src="figures/introduction-descr-examples-1.png" alt="Two examples of how descriptive models can be used to illustrate specific patterns." width="80%" />
<p class="caption">
Figure 1.1: Two examples of how descriptive models can be used to illustrate specific patterns.
</p>
</div>
<p>Another example of a descriptive model is the <em>locally estimated scatterplot smoothing</em> model, more commonly known as LOESS <span class="citation">(Cleveland <a href="#ref-cleveland1979">1979</a>)</span>. Here, a smooth and flexible regression model is fit to a data set, usually with a single independent variable, and the fitted regression line is used to elucidate some trend in the data. These types of <em>smoothers</em> are used to discover potential ways to represent a variable in a model. This is demonstrated in Figure <a href="introduction.html#fig:descr-examples">1.1</a>(b) where a nonlinear trend is illuminated by the flexible smoother.</p>
<p><strong>Inferential Models</strong>: In these situations, the goal is to produce a decision for a research question or to test a specific hypothesis. The goal is to make some statement of truth regarding some predefined conjecture or idea. In many (but not all) cases, some qualitative statement is produced.</p>
<p>For example, in a clinical trial, the goal might be to provide confirmation that a new therapy does a better job in prolonging life than an alternative (e.g., an existing therapy or no treatment). If the clinical endpoint was related to survival or a patient, the <em>null hypothesis</em> might be that the two therapeutic groups have equal median survival times with the alternative hypothesis being that the new therapy has higher median survival. If this trial were evaluated using the traditional <em>null hypothesis significance testing</em> (NHST), a p-value would be produced using some pre-defined methodology based on a set of assumptions for the data. Small values of the p-value indicate that there is evidence that the new therapy does help patients live longer. If not, the conclusion is that there is a failure to show such an difference (which could be due to a number of reasons).</p>
<p>What are the important aspects of this type of analysis? Inferential techniques typically produce some type of probabilistic output, such as a p-value, confidence interval, or posterior probability. Generally, to compute such a quantity, formal assumptions must be made about the data and the underlying processes that generated the data. The quality of the statistical results are highly dependent on these pre-defined assumptions as well as how much the observed data appear to agree with them. The most critical factors here are theoretical in nature: if my data were independent and follow distribution <em>X</em>, then test statistic <em>Y</em> can be used to produce a p-value. Otherwise, the resulting p-value might be inaccurate.</p>
<p>One aspect of inferential analyses is that there <em>tends</em> to be a longer feedback loop that could help understand how well the data fit the assumptions. In our clinical trial example, if statistical (and clinical) significance indicated that the new therapy should be available for patients to use, it may be years before it is used in the field and enough data were generated to have an independent assessment of whether the original statistical analysis led to the appropriate decision.</p>
<p><strong>Predictive Models</strong>: There are occasions where data are modeled in an effort to produce the most accurate prediction possible for new data. Here, the primary goal is that the predicted values have the highest possible fidelity to the true value of the new data.</p>
<p>A simple example would be for a book buyer to predict how many copies of a particular book should be shipped to his/her store for the next month. An over-prediction wastes space and money due to excess books. If the prediction is smaller than it should be, there is opportunity loss and less profit.</p>
<p>For this type of model, the problem type is one of <em>estimation</em> rather than inference. For example, the buyer is usually not concerned with a question such as “Will I sell more than 100 copies of book <em>X</em> next month?” but rather “How many copies of <em>X</em> will customers purchase next month?” Also, depending on the context, there may not be any interest in <em>why</em> the predicted value is <em>X</em>. In other words, is more interest in the value itself than evaluating a formal hypothesis related to the data. That said, the prediction can also include measures of uncertainty. In the case of the book buyer, some sort of forecasting error might be valuable to help them decide on how many to purchase or could serve as a metric to gauge how well the prediction method worked.</p>
<p>What are the most important factors affecting predictive models? There are many different ways that a predictive model could be created. The important factors depend on how the model was developed.</p>
<p>For example, a <em>mechanistic model</em> could be developed based on first principles to produce a model equation that is dependent on assumptions. For example, when predicting the amount of a drug that is in a person’s body at a certain time, some formal assumptions are made on how the drug is administered, absorbed, metabolized, and eliminated. Based on this, a set of differential equations can be used to derive a specific model equation. Data are used to estimate the known parameters of this equation and predictions are made after parameter estimation. Like inferential models, mechanistic predictive models greatly depend on the assumptions that define their model equations. However, unlike inferential models, it is easy to make data-driven statements about how well the model performs based on how well it predicts the existing data. Here the feedback loop for the modeler is much faster than it would be for a hypothesis test.</p>
<p><em>Empirically driven models</em> are those that have more vague assumptions that are used to create their model equations. These models tend to fall more into the machine learning category. A good example is the simple <em>K</em>-nearest neighbor (KNN) model. Given a set of reference data, a new sample is predicted by using the values of the most similar data in the reference set. For example, if a book buyer needs a prediction for a new book, historical data from existing books may be available. A 5-nearest neighbor model would estimate the amount of the new book to purchase based on the sales numbers of the five books that are most similar to the new one (for some definition of “similar”). This model is only defined by the structure of the prediction (the average of five similar books). No theoretical or probabilistic assumptions are made about the sales numbers or the variables that are used to define similarity. In fact, the primary method of evaluating the appropriateness of the model is to assess its accuracy using existing data. If the structure of this type of model was a good choice, the predictions would not be close to the actual values.</p>
<p>Broader discussions of these distinctions can be found in <span class="citation">Breiman (<a href="#ref-breiman2001">2001</a>)</span> and <span class="citation">Shmueli (<a href="#ref-shmueli2010">2010</a>)</span>. Note that we have defined the type of model by how it is used rather than its mathematical qualities. An ordinary linear regression model might fall into all three classes of models, depending on how it is used:</p>
<ul>
<li><p>Descriptive smoother, similar to LOESS, called <em>restricted smoothing splines</em> <span class="citation">(Durrleman and Simon <a href="#ref-Durrleman1989">1989</a>)</span> can be used to describe trends in data using ordinary linear regression with specialized terms.</p></li>
<li><p>An <em>analysis of variance</em> (ANOVA) model is a popular method for producing the p-values used for inference. ANOVA models are a special case of linear regression.</p></li>
<li><p>If a simple linear regression model produces highly accurate predictions, it can be used as a predictive model.</p></li>
</ul>
<p>However, there are many more examples of predictive models that cannot (or at least should not) be used for inference. Even if probabilistic assumptions were made for the data, the nature of the KNN model makes the math required for inference intractable.</p>
<p>There is an additional connection between the types of models. While the primary purpose of descriptive and inferential models might not be related to prediction, the predictive capacity of the model should not be ignored. For example, logistic regression is a popular model for data where the outcome is qualitative with two possible values. It can model how variables related to the probability of the outcomes. When used in an inferential manner, there is usually an abundance of attention paid to the <em>statistical qualities</em> of the model. For example, analysts tend to strongly focus on the selection of which independent variables are contained in the model. Many iterations of model building are usually used to determine a minimal subset of independent variables that have a “statistically significant” relationship to the outcome variable. This is usually achieved when all of the p-values for the independent variables are below some value (e.g. 0.05). From here, the analyst typically focuses on making qualitative statements about the relative influence that the variables have on the outcome.</p>
<p>A potential problem with this approach is that it can be dangerous when statistical significance is used as the <em>only</em> measure of model quality. It is certainly possible that this statistically optimized model has poor model accuracy (or some other measure of predictive capacity). While the model might not be used for prediction, how much should the inferences be trusted from a model that has all significant p-values but a dismal accuracy? Predictive performance tends to be related to how close the model’s fitted values are to the observed data. If the model has limited fidelity to the data, the inferences generated by the model should be highly suspect. In other words, statistical significance may not imply that the model should be used. This may seem intuitively obvious, but is often ignored in real-world data analysis.</p>
</div>
<div id="some-terminology" class="section level2">
<h2><span class="header-section-number">1.2</span> Some terminology</h2>
<p>supervise, unsupervised</p>
<p>types of variables</p>
<p>types of predictors</p>
<p>The mode of the model: regression, classification</p>
</div>
<div id="where-does-modeling-fit-into-the-data-analysisscientific-process" class="section level2">
<h2><span class="header-section-number">1.3</span> Where does modeling fit into the data analysis/scientific process?</h2>
<p>(probably need to get explicit permission to use this)</p>
<div class="figure" style="text-align: center"><span id="fig:data-science-model"></span>
<img src="figures-premade/data-science-model.svg" alt="The data science process (from _R for Data Science_)." width="80%" />
<p class="caption">
Figure 1.2: The data science process (from <em>R for Data Science</em>).
</p>
</div>
</div>
<div id="modeling-is-a-process-not-a-single-activity" class="section level2">
<h2><span class="header-section-number">1.4</span> Modeling is a <em>process</em>, not a single activity</h2>
<p>(probably need to get explicit permission to use this too)</p>
<div class="figure" style="text-align: center"><span id="fig:modeling-process"></span>
<img src="figures/introduction-modeling-process-1.svg" alt="A schematic for the typical modeling process." width="100%" />
<p class="caption">
Figure 1.3: A schematic for the typical modeling process.
</p>
</div>
</div>
<div id="outline-of-future-chapters" class="section level2">
<h2><span class="header-section-number">1.5</span> Outline of future chapters</h2>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-abrams2003">
<p>Abrams, B. 2003. “The Pit of Success.” <a href="https://blogs.msdn.microsoft.com/brada/2003/10/02/the-pit-of-success/">https://blogs.msdn.microsoft.com/brada/2003/10/02/the-pit-of-success/</a>.</p>
</div>
<div id="ref-baggerly2009">
<p>Baggerly, K, and K Coombes. 2009. “Deriving Chemosensitivity from Cell Lines: Forensic Bioinformatics and Reproducible Research in High-Throughput Biology.” <em>The Annals of Applied Statistics</em> 3 (4): 1309–34.</p>
</div>
<div id="ref-bolstad2004">
<p>Bolstad, B. 2004. <em>Low-Level Analysis of High-Density Oligonucleotide Array Data: Background, Normalization and Summarization</em>. University of California, Berkeley.</p>
</div>
<div id="ref-breiman2001">
<p>Breiman, L. 2001. “Statistical Modeling: The Two Cultures.” <em>Statistical Science</em> 16 (3): 199–231.</p>
</div>
<div id="ref-Carlson2012">
<p>Carlson, B. 2012. “Putting Oncology Patients at Risk.” <em>Biotechnology Healthcare</em> 9 (3): 17–21.</p>
</div>
<div id="ref-Chambers:1998">
<p>Chambers, J. 1998. <em>Programming with Data: A Guide to the S Language</em>. Berlin, Heidelberg: Springer-Verlag.</p>
</div>
<div id="ref-cleveland1979">
<p>Cleveland, W. 1979. “Robust Locally Weighted Regression and Smoothing Scatterplots.” <em>Journal of the American Statistical Association</em> 74 (368): 829–36.</p>
</div>
<div id="ref-Durrleman1989">
<p>Durrleman, S, and R Simon. 1989. “Flexible Regression Models with Cubic Splines.” <em>Statistics in Medicine</em> 8 (5): 551–61.</p>
</div>
<div id="ref-Gentleman2005">
<p>Gentleman, R, V Carey, W Huber, R Irizarry, and S Dudoit. 2005. <em>Bioinformatics and Computational Biology Solutions Using R and Bioconductor</em>. Berlin, Heidelberg: Springer-Verlag.</p>
</div>
<div id="ref-baseR">
<p>R Core Team. 2014. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="http://www.R-project.org/">http://www.R-project.org/</a>.</p>
</div>
<div id="ref-shmueli2010">
<p>Shmueli, G. 2010. “To Explain or to Predict?” <em>Statistical Science</em> 25 (3). Institute of Mathematical Statistics: 289–310.</p>
</div>
<div id="ref-tidyverse">
<p>Wickham, H, M Averick, J Bryan, W Chang, L McGowan, R François, G Grolemund, et al. 2019. “Welcome to the Tidyverse.” <em>Journal of Open Source Software</em> 4 (43).</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="a-tidyverse-primer.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/topepo/TMwR-temp/edit/master/introduction.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
